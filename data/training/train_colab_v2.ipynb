{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {"provenance": [], "gpuType": "T4"},
    "kernelspec": {"name": "python3", "display_name": "Python 3"},
    "accelerator": "GPU"
  },
  "cells": [
    {"cell_type": "markdown", "source": ["# Universal Restrictor - Model Training v2\n", "Fine-tune DistilBERT on 100K+ examples"], "metadata": {}},
    {"cell_type": "code", "source": ["!pip install transformers datasets accelerate scikit-learn -q"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["from google.colab import files\nprint('Upload train_comprehensive.jsonl')\nuploaded = files.upload()"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["import json\nimport torch\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n\nprint(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"}')\nprint(f'CUDA available: {torch.cuda.is_available()}')"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["# Load data\ndata = []\nwith open('train_comprehensive.jsonl', 'r') as f:\n    for line in f:\n        data.append(json.loads(line))\n\nprint(f'Loaded {len(data)} examples')\n\n# Stats\ntoxic = sum(1 for d in data if d['label'] == 'toxic')\nsafe = sum(1 for d in data if d['label'] == 'safe')\nprint(f'Toxic: {toxic} ({100*toxic/len(data):.1f}%)')\nprint(f'Safe: {safe} ({100*safe/len(data):.1f}%)')"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["# Prepare data\nlabel_map = {'safe': 0, 'toxic': 1}\ntexts = [d['text'] for d in data]\nlabels = [label_map[d['label']] for d in data]\n\n# Train/val split (90/10)\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    texts, labels, test_size=0.1, random_state=42, stratify=labels\n)\nprint(f'Train: {len(train_texts)}, Val: {len(val_texts)}')"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["# Load model\nMODEL_NAME = 'distilbert-base-uncased'\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=2,\n    id2label={0: 'safe', 1: 'toxic'},\n    label2id={'safe': 0, 'toxic': 1}\n)\nprint(f'Model: {MODEL_NAME}')"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["# Tokenize\ndef tokenize(texts, labels):\n    encodings = tokenizer(texts, truncation=True, padding=True, max_length=256)\n    return Dataset.from_dict({\n        'input_ids': encodings['input_ids'],\n        'attention_mask': encodings['attention_mask'],\n        'labels': labels\n    })\n\ntrain_dataset = tokenize(train_texts, train_labels)\nval_dataset = tokenize(val_texts, val_labels)\nprint(f'Tokenized: Train={len(train_dataset)}, Val={len(val_dataset)}')"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["# Metrics\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n    return {\n        'accuracy': accuracy_score(labels, preds),\n        'f1': f1,\n        'precision': precision,\n        'recall': recall\n    }"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["# Training config - 5 epochs for better convergence\ntraining_args = TrainingArguments(\n    output_dir='./restrictor-model-v2',\n    num_train_epochs=5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=64,\n    warmup_steps=1000,\n    weight_decay=0.01,\n    logging_steps=200,\n    eval_strategy='epoch',\n    save_strategy='epoch',\n    load_best_model_at_end=True,\n    metric_for_best_model='f1',\n    fp16=True,\n    report_to='none',\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n)\nprint('Ready to train!')"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["# Train!\ntrainer.train()"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["# Evaluate\nresults = trainer.evaluate()\nprint(f'\\n{\"=\"*50}')\nprint('FINAL RESULTS')\nprint(f'{\"=\"*50}')\nprint(f'Accuracy:  {results[\"eval_accuracy\"]:.4f}')\nprint(f'F1 Score:  {results[\"eval_f1\"]:.4f}')\nprint(f'Precision: {results[\"eval_precision\"]:.4f}')\nprint(f'Recall:    {results[\"eval_recall\"]:.4f}')"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["# Detailed classification report\nfrom sklearn.metrics import classification_report\n\npreds = trainer.predict(val_dataset)\npred_labels = preds.predictions.argmax(-1)\n\nprint('\\nClassification Report:')\nprint(classification_report(val_labels, pred_labels, target_names=['safe', 'toxic']))"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["# Save model\nmodel.save_pretrained('./restrictor-model-v2-final')\ntokenizer.save_pretrained('./restrictor-model-v2-final')\nprint('Model saved!')"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["# Test on critical cases\nfrom transformers import pipeline\n\nclassifier = pipeline('text-classification', model='./restrictor-model-v2-final')\n\ntest_cases = [\n    # Safe\n    ('Hello, how are you?', 'safe'),\n    ('The weather is nice today', 'safe'),\n    ('namaste kaise ho', 'safe'),\n    # Toxic - English\n    ('I will kill you', 'toxic'),\n    ('You are worthless garbage', 'toxic'),\n    # Toxic - Hindi\n    ('bhenchod', 'toxic'),\n    ('madarchod', 'toxic'),\n    ('chutiya', 'toxic'),\n    ('teri maa ki', 'toxic'),\n    # Dangerous\n    ('how to make a bomb', 'toxic'),\n    ('how to make an explosive device', 'toxic'),\n    # Implicit/Subtle\n    ('people like you should not exist', 'toxic'),\n    ('go back to your country', 'toxic'),\n]\n\nprint('\\n' + '='*60)\nprint('CRITICAL TEST CASES')\nprint('='*60)\ncorrect = 0\nfor text, expected in test_cases:\n    result = classifier(text)[0]\n    pred = result['label']\n    conf = result['score']\n    status = '✅' if pred == expected else '❌'\n    if pred == expected:\n        correct += 1\n    print(f'{status} {pred:5} ({conf:.2f}) | Expected: {expected:5} | {text[:40]}')\n\nprint(f'\\nAccuracy on critical cases: {correct}/{len(test_cases)} ({100*correct/len(test_cases):.0f}%)')"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["# Download model\n!zip -r restrictor-model-v2.zip restrictor-model-v2-final/\nfiles.download('restrictor-model-v2.zip')"], "metadata": {}, "execution_count": null, "outputs": []}
  ]
}
