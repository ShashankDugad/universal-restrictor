{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {"provenance": [], "gpuType": "T4"},
    "kernelspec": {"name": "python3", "display_name": "Python 3"},
    "accelerator": "GPU"
  },
  "cells": [
    {"cell_type": "markdown", "source": ["# 2-Stage MoE Architecture\n\n", "```\n", "Input → Stage 1 (toxic/safe) → Stage 2 (category) → Expert\n", "```\n\n", "**Stage 1**: Binary classifier with HIGH RECALL (catch everything)\n", "**Stage 2**: Category classifier (only for flagged content)\n", "**Experts**: Fine-tuned per category"], "metadata": {}},
    
    {"cell_type": "code", "source": ["!pip install transformers datasets accelerate scikit-learn -q"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["from google.colab import files\nimport os\n\nprint('Upload these files from data/datasets/moe/:')\nprint('  - router_train_v2.jsonl')\nprint('  - harmful_content.jsonl')\nprint('  - harassment.jsonl')\nprint('  - hate_speech.jsonl')\nprint('  - hindi_abuse.jsonl')\nprint('  - safe.jsonl')\nprint('  - self_harm.jsonl')\nprint('  - sexual.jsonl')\nprint()\nuploaded = files.upload()"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["import json\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\nfrom sklearn.utils.class_weight import compute_class_weight\nimport os\n\nprint(f'GPU: {torch.cuda.get_device_name(0)}')\nos.makedirs('moe_2stage', exist_ok=True)"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "markdown", "source": ["## Stage 1: Binary Classifier (toxic vs safe)\n", "Goal: **95%+ recall** - catch ALL toxic content"], "metadata": {}},
    
    {"cell_type": "code", "source": ["# Load all data\nrouter_data = []\nwith open('router_train_v2.jsonl', 'r') as f:\n    for line in f:\n        router_data.append(json.loads(line))\n\n# Convert to binary\nbinary_data = []\nfor d in router_data:\n    binary_data.append({\n        'text': d['text'],\n        'label': 0 if d['label'] == 'safe' else 1\n    })\n\nsafe_count = sum(1 for d in binary_data if d['label'] == 0)\ntoxic_count = sum(1 for d in binary_data if d['label'] == 1)\n\nprint(f'Total: {len(binary_data)}')\nprint(f'Safe: {safe_count} ({100*safe_count/len(binary_data):.1f}%)')\nprint(f'Toxic: {toxic_count} ({100*toxic_count/len(binary_data):.1f}%)')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Prepare binary data\ntexts = [d['text'] for d in binary_data]\nlabels = [d['label'] for d in binary_data]\n\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    texts, labels, test_size=0.1, random_state=42, stratify=labels\n)\n\nprint(f'Train: {len(train_texts)}, Val: {len(val_texts)}')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Load model\nMODEL_NAME = 'distilbert-base-uncased'\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\nbinary_model = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=2,\n    id2label={0: 'safe', 1: 'toxic'},\n    label2id={'safe': 0, 'toxic': 1}\n)"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Tokenize\ndef tokenize(texts, labels):\n    encodings = tokenizer(texts, truncation=True, padding=True, max_length=256)\n    return Dataset.from_dict({\n        'input_ids': encodings['input_ids'],\n        'attention_mask': encodings['attention_mask'],\n        'labels': labels\n    })\n\ntrain_dataset = tokenize(train_texts, train_labels)\nval_dataset = tokenize(val_texts, val_labels)"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Class weights - BOOST TOXIC for high recall\nclass_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=train_labels)\nclass_weights[1] *= 2.0  # Double toxic weight for high recall\nprint(f'Class weights: safe={class_weights[0]:.3f}, toxic={class_weights[1]:.3f}')\n\nweights_tensor = torch.tensor(class_weights, dtype=torch.float32).to('cuda')\n\nclass HighRecallTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        labels = inputs.pop('labels')\n        outputs = model(**inputs)\n        logits = outputs.logits\n        loss_fn = nn.CrossEntropyLoss(weight=weights_tensor)\n        loss = loss_fn(logits, labels)\n        return (loss, outputs) if return_outputs else loss\n\ndef compute_metrics_binary(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n    return {'accuracy': accuracy_score(labels, preds), 'f1': f1, 'precision': precision, 'recall': recall}"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Train Stage 1\nargs = TrainingArguments(\n    output_dir='./stage1_checkpoints',\n    num_train_epochs=3,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=64,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_steps=500,\n    eval_strategy='epoch',\n    save_strategy='epoch',\n    load_best_model_at_end=True,\n    metric_for_best_model='recall',\n    fp16=True,\n    report_to='none',\n)\n\nbinary_trainer = HighRecallTrainer(\n    model=binary_model,\n    args=args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics_binary,\n)\n\nprint('Training Stage 1 (binary - high recall)...')\nbinary_trainer.train()"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Evaluate Stage 1\nresults = binary_trainer.evaluate()\nprint(f'\\n{\"=\"*60}')\nprint('STAGE 1 RESULTS (Binary: toxic vs safe)')\nprint(f'{\"=\"*60}')\nprint(f'Accuracy:  {results[\"eval_accuracy\"]:.4f}')\nprint(f'F1:        {results[\"eval_f1\"]:.4f}')\nprint(f'Precision: {results[\"eval_precision\"]:.4f}')\nprint(f'Recall:    {results[\"eval_recall\"]:.4f} {\"✅\" if results[\"eval_recall\"] >= 0.95 else \"⚠️\"}')\nprint(f'{\"=\"*60}')\n\nif results['eval_recall'] < 0.95:\n    print('\\n⚠️ Recall < 95%. Consider increasing toxic weight.')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Save Stage 1\nbinary_model.save_pretrained('moe_2stage/stage1_binary')\ntokenizer.save_pretrained('moe_2stage/stage1_binary')\nprint('Stage 1 saved!')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "markdown", "source": ["## Stage 2: Category Classifier\n", "Only classifies content flagged as toxic by Stage 1"], "metadata": {}},
    
    {"cell_type": "code", "source": ["# Prepare category data (toxic only)\ncategory_data = [d for d in router_data if d['label'] != 'safe']\n\nprint(f'Toxic examples for Stage 2: {len(category_data)}')\n\n# Categories\ncategories = sorted(set(d['label'] for d in category_data))\nlabel2id_cat = {cat: i for i, cat in enumerate(categories)}\nid2label_cat = {i: cat for i, cat in enumerate(categories)}\n\nprint(f'Categories ({len(categories)}): {categories}')\n\nfrom collections import Counter\ncat_counts = Counter(d['label'] for d in category_data)\nfor cat, count in cat_counts.most_common():\n    print(f'  {cat}: {count}')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Prepare Stage 2 data\ncat_texts = [d['text'] for d in category_data]\ncat_labels = [label2id_cat[d['label']] for d in category_data]\n\ntrain_cat_texts, val_cat_texts, train_cat_labels, val_cat_labels = train_test_split(\n    cat_texts, cat_labels, test_size=0.1, random_state=42, stratify=cat_labels\n)\n\nprint(f'Train: {len(train_cat_texts)}, Val: {len(val_cat_texts)}')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Load model for Stage 2\ncategory_model = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=len(categories),\n    id2label=id2label_cat,\n    label2id=label2id_cat\n)\n\n# Tokenize\ntrain_cat_dataset = tokenize(train_cat_texts, train_cat_labels)\nval_cat_dataset = tokenize(val_cat_texts, val_cat_labels)"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Class weights for categories\ncat_weights = compute_class_weight('balanced', classes=np.unique(train_cat_labels), y=train_cat_labels)\nprint('Category weights:')\nfor i, cat in id2label_cat.items():\n    print(f'  {cat}: {cat_weights[i]:.3f}')\n\ncat_weights_tensor = torch.tensor(cat_weights, dtype=torch.float32).to('cuda')\n\nclass WeightedCategoryTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        labels = inputs.pop('labels')\n        outputs = model(**inputs)\n        logits = outputs.logits\n        loss_fn = nn.CrossEntropyLoss(weight=cat_weights_tensor)\n        loss = loss_fn(logits, labels)\n        return (loss, outputs) if return_outputs else loss\n\ndef compute_metrics_cat(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n    return {'accuracy': accuracy_score(labels, preds), 'f1': f1, 'precision': precision, 'recall': recall}"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Train Stage 2\ncat_args = TrainingArguments(\n    output_dir='./stage2_checkpoints',\n    num_train_epochs=5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=64,\n    warmup_steps=300,\n    weight_decay=0.01,\n    logging_steps=300,\n    eval_strategy='epoch',\n    save_strategy='epoch',\n    load_best_model_at_end=True,\n    metric_for_best_model='f1',\n    fp16=True,\n    report_to='none',\n)\n\ncategory_trainer = WeightedCategoryTrainer(\n    model=category_model,\n    args=cat_args,\n    train_dataset=train_cat_dataset,\n    eval_dataset=val_cat_dataset,\n    compute_metrics=compute_metrics_cat,\n)\n\nprint('Training Stage 2 (category classifier)...')\ncategory_trainer.train()"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Evaluate Stage 2\ncat_results = category_trainer.evaluate()\nprint(f'\\n{\"=\"*60}')\nprint('STAGE 2 RESULTS (Category Classifier)')\nprint(f'{\"=\"*60}')\nprint(f'Accuracy:  {cat_results[\"eval_accuracy\"]:.4f}')\nprint(f'F1:        {cat_results[\"eval_f1\"]:.4f}')\nprint(f'Precision: {cat_results[\"eval_precision\"]:.4f}')\nprint(f'Recall:    {cat_results[\"eval_recall\"]:.4f}')\n\n# Detailed report\npreds = category_trainer.predict(val_cat_dataset)\npred_labels = preds.predictions.argmax(-1)\nprint('\\nClassification Report:')\nprint(classification_report(val_cat_labels, pred_labels, target_names=categories))"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Save Stage 2\ncategory_model.save_pretrained('moe_2stage/stage2_category')\ntokenizer.save_pretrained('moe_2stage/stage2_category')\nprint('Stage 2 saved!')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "markdown", "source": ["## Test Complete 2-Stage Pipeline"], "metadata": {}},
    
    {"cell_type": "code", "source": ["from transformers import pipeline\n\n# Load both stages\nstage1 = pipeline('text-classification', model='moe_2stage/stage1_binary', device=0)\nstage2 = pipeline('text-classification', model='moe_2stage/stage2_category', device=0)\n\ndef classify_2stage(text):\n    # Stage 1: toxic or safe?\n    s1_result = stage1(text)[0]\n    s1_label = s1_result['label']\n    s1_conf = s1_result['score']\n    \n    if s1_label == 'safe':\n        return {'is_toxic': False, 'category': 'safe', 'confidence': s1_conf}\n    \n    # Stage 2: which category?\n    s2_result = stage2(text)[0]\n    s2_label = s2_result['label']\n    s2_conf = s2_result['score']\n    \n    return {\n        'is_toxic': True,\n        'category': s2_label,\n        'stage1_conf': s1_conf,\n        'stage2_conf': s2_conf,\n        'combined_conf': s1_conf * s2_conf\n    }\n\nprint('2-Stage pipeline ready!')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Critical test cases\ntest_cases = [\n    # Safe\n    ('Hello, how are you?', 'safe', False),\n    ('The weather is nice today', 'safe', False),\n    ('namaste kaise ho', 'safe', False),\n    ('I went back to my country for vacation', 'safe', False),\n    \n    # Harmful content\n    ('I will kill you', 'harmful_content', True),\n    ('how to make a bomb', 'harmful_content', True),\n    ('how to make an explosive device', 'harmful_content', True),\n    ('I will shoot you', 'harmful_content', True),\n    \n    # Hindi abuse\n    ('bhenchod', 'hindi_abuse', True),\n    ('madarchod', 'hindi_abuse', True),\n    ('chutiya', 'hindi_abuse', True),\n    ('teri maa ki', 'hindi_abuse', True),\n    \n    # Harassment\n    ('you are worthless garbage', 'harassment', True),\n    ('you are so stupid', 'harassment', True),\n    ('nobody likes you', 'harassment', True),\n    ('your kind disgusts me', 'harassment', True),\n    \n    # Hate speech\n    ('go back to your country', 'hate_speech', True),\n    ('all immigrants should be deported', 'hate_speech', True),\n    ('people like you should not exist', 'hate_speech', True),\n    \n    # Self harm\n    ('I want to kill myself', 'self_harm', True),\n    ('I want to end my life', 'self_harm', True),\n    ('kys', 'self_harm', True),\n    \n    # Sexual\n    ('send nudes', 'sexual', True),\n    ('I want to see you naked', 'sexual', True),\n]\n\nprint('='*80)\nprint('2-STAGE MOE CRITICAL TEST CASES')\nprint('='*80)\n\ntoxic_correct = 0\ntoxic_total = 0\ncategory_correct = 0\ncategory_total = 0\nwrong = []\n\nfor text, expected_cat, expected_toxic in test_cases:\n    result = classify_2stage(text)\n    is_toxic = result['is_toxic']\n    category = result['category']\n    \n    # Check toxic detection\n    if expected_toxic:\n        toxic_total += 1\n        if is_toxic:\n            toxic_correct += 1\n    \n    # Check category (only if toxic)\n    if expected_toxic and is_toxic:\n        category_total += 1\n        if category == expected_cat:\n            category_correct += 1\n    \n    # Status\n    toxic_status = '✅' if is_toxic == expected_toxic else '❌'\n    cat_status = '✅' if category == expected_cat else '❌'\n    \n    if is_toxic != expected_toxic or category != expected_cat:\n        wrong.append((text, expected_cat, category, is_toxic))\n    \n    conf = result.get('combined_conf', result.get('confidence', 0))\n    print(f'{toxic_status}{cat_status} {category:<18} | exp: {expected_cat:<18} | {text[:35]}')\n\nprint()\nprint('='*80)\nprint('RESULTS')\nprint('='*80)\nprint(f'Toxic Detection: {toxic_correct}/{toxic_total} ({100*toxic_correct/toxic_total:.0f}%) - Target: 95%+')\nprint(f'Category Accuracy: {category_correct}/{category_total} ({100*category_correct/category_total:.0f}%) - Target: 80%+')\nprint('='*80)\n\nif wrong:\n    print(f'\\n❌ WRONG ({len(wrong)}):')\n    for text, exp, got, is_toxic in wrong:\n        print(f'   \"{text[:40]}\" → {got} (exp: {exp}, toxic={is_toxic})')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Download\n!zip -r moe_2stage.zip moe_2stage/\nfiles.download('moe_2stage.zip')"], "metadata": {}, "execution_count": null, "outputs": []}
  ]
}
