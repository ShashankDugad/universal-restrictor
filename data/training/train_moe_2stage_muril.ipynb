{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {"provenance": [], "gpuType": "T4"},
    "kernelspec": {"name": "python3", "display_name": "Python 3"},
    "accelerator": "GPU"
  },
  "cells": [
    {"cell_type": "markdown", "source": ["# 2-Stage MoE with MuRIL\n\n", "**Model**: `google/muril-base-cased` - Best for Indian languages\n\n", "```\n", "Input → Stage 1 (toxic/safe) → Stage 2 (category)\n", "```\n\n", "**Stage 1**: Binary classifier with HIGH RECALL\n", "**Stage 2**: Category classifier for toxic content"], "metadata": {}},
    
    {"cell_type": "code", "source": ["!pip install transformers datasets accelerate scikit-learn sentencepiece -q"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["from google.colab import files\nimport os\n\nprint('Upload these files from data/datasets/moe/:')\nprint('  - router_train_v2.jsonl')\nprint()\nuploaded = files.upload()"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["import json\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\nfrom sklearn.utils.class_weight import compute_class_weight\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(f'GPU: {torch.cuda.get_device_name(0)}')\nprint(f'CUDA: {torch.cuda.is_available()}')\n\nos.makedirs('moe_muril', exist_ok=True)\n\n# MuRIL - Best for Indian languages\nMODEL_NAME = 'google/muril-base-cased'\nprint(f'Model: {MODEL_NAME}')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nprint(f'Tokenizer loaded: {MODEL_NAME}')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "markdown", "source": ["---\n", "## Stage 1: Binary Classifier (toxic vs safe)\n", "**Goal: 95%+ recall** - catch ALL toxic content"], "metadata": {}},
    
    {"cell_type": "code", "source": ["# Load all data\nrouter_data = []\nwith open('router_train_v2.jsonl', 'r') as f:\n    for line in f:\n        router_data.append(json.loads(line))\n\n# Convert to binary\nbinary_data = []\nfor d in router_data:\n    binary_data.append({\n        'text': d['text'],\n        'label': 0 if d['label'] == 'safe' else 1  # 0=safe, 1=toxic\n    })\n\nsafe_count = sum(1 for d in binary_data if d['label'] == 0)\ntoxic_count = sum(1 for d in binary_data if d['label'] == 1)\n\nprint(f'Total: {len(binary_data)}')\nprint(f'Safe: {safe_count} ({100*safe_count/len(binary_data):.1f}%)')\nprint(f'Toxic: {toxic_count} ({100*toxic_count/len(binary_data):.1f}%)')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Prepare binary data\ntexts = [d['text'] for d in binary_data]\nlabels = [d['label'] for d in binary_data]\n\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    texts, labels, test_size=0.1, random_state=42, stratify=labels\n)\n\nprint(f'Train: {len(train_texts)}')\nprint(f'Val: {len(val_texts)}')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Tokenize function\ndef tokenize_data(texts, labels):\n    encodings = tokenizer(\n        texts, \n        truncation=True, \n        padding=True, \n        max_length=256,\n        return_tensors=None\n    )\n    return Dataset.from_dict({\n        'input_ids': encodings['input_ids'],\n        'attention_mask': encodings['attention_mask'],\n        'labels': labels\n    })\n\nprint('Tokenizing Stage 1 data...')\ntrain_dataset = tokenize_data(train_texts, train_labels)\nval_dataset = tokenize_data(val_texts, val_labels)\nprint(f'Done! Train: {len(train_dataset)}, Val: {len(val_dataset)}')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Load binary model\nbinary_model = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=2,\n    id2label={0: 'safe', 1: 'toxic'},\n    label2id={'safe': 0, 'toxic': 1}\n)\nprint('Binary model loaded!')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Class weights - BOOST TOXIC for high recall\nclass_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=train_labels)\nclass_weights[1] *= 2.0  # Double toxic weight\nprint(f'Class weights: safe={class_weights[0]:.3f}, toxic={class_weights[1]:.3f}')\n\nweights_tensor = torch.tensor(class_weights, dtype=torch.float32).to('cuda')\n\nclass HighRecallTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        labels = inputs.pop('labels')\n        outputs = model(**inputs)\n        logits = outputs.logits\n        loss_fn = nn.CrossEntropyLoss(weight=weights_tensor)\n        loss = loss_fn(logits, labels)\n        return (loss, outputs) if return_outputs else loss\n\ndef compute_metrics_binary(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n    return {\n        'accuracy': accuracy_score(labels, preds), \n        'f1': f1, \n        'precision': precision, \n        'recall': recall\n    }"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Train Stage 1\nbinary_args = TrainingArguments(\n    output_dir='./stage1_checkpoints',\n    num_train_epochs=3,\n    per_device_train_batch_size=16,  # Smaller batch for MuRIL\n    per_device_eval_batch_size=32,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_steps=500,\n    eval_strategy='epoch',\n    save_strategy='epoch',\n    load_best_model_at_end=True,\n    metric_for_best_model='recall',  # Optimize for RECALL\n    fp16=True,\n    report_to='none',\n    gradient_accumulation_steps=2,  # Effective batch size = 32\n)\n\nbinary_trainer = HighRecallTrainer(\n    model=binary_model,\n    args=binary_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics_binary,\n)\n\nprint('='*60)\nprint('TRAINING STAGE 1: Binary (toxic vs safe)')\nprint('='*60)\nbinary_trainer.train()"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Evaluate Stage 1\nresults1 = binary_trainer.evaluate()\nprint(f'\\n{\"=\"*60}')\nprint('STAGE 1 RESULTS')\nprint(f'{\"=\"*60}')\nprint(f'Accuracy:  {results1[\"eval_accuracy\"]:.4f}')\nprint(f'F1:        {results1[\"eval_f1\"]:.4f}')\nprint(f'Precision: {results1[\"eval_precision\"]:.4f}')\nprint(f'Recall:    {results1[\"eval_recall\"]:.4f} {\"✅ GOOD\" if results1[\"eval_recall\"] >= 0.93 else \"⚠️ LOW\"}')\nprint(f'{\"=\"*60}')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Save Stage 1\nbinary_model.save_pretrained('moe_muril/stage1_binary')\ntokenizer.save_pretrained('moe_muril/stage1_binary')\nprint('✅ Stage 1 saved to moe_muril/stage1_binary')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "markdown", "source": ["---\n", "## Stage 2: Category Classifier\n", "Classifies toxic content into categories"], "metadata": {}},
    
    {"cell_type": "code", "source": ["# Prepare category data (toxic only)\ncategory_data = [d for d in router_data if d['label'] != 'safe']\n\nprint(f'Toxic examples: {len(category_data)}')\n\n# Get categories\ncategories = sorted(set(d['label'] for d in category_data))\nlabel2id_cat = {cat: i for i, cat in enumerate(categories)}\nid2label_cat = {i: cat for i, cat in enumerate(categories)}\n\nprint(f'\\nCategories ({len(categories)}):')\nfrom collections import Counter\nfor cat, count in Counter(d['label'] for d in category_data).most_common():\n    print(f'  {cat}: {count}')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Prepare Stage 2 data\ncat_texts = [d['text'] for d in category_data]\ncat_labels = [label2id_cat[d['label']] for d in category_data]\n\ntrain_cat_texts, val_cat_texts, train_cat_labels, val_cat_labels = train_test_split(\n    cat_texts, cat_labels, test_size=0.1, random_state=42, stratify=cat_labels\n)\n\nprint(f'Train: {len(train_cat_texts)}')\nprint(f'Val: {len(val_cat_texts)}')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Tokenize Stage 2\nprint('Tokenizing Stage 2 data...')\ntrain_cat_dataset = tokenize_data(train_cat_texts, train_cat_labels)\nval_cat_dataset = tokenize_data(val_cat_texts, val_cat_labels)\nprint('Done!')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Load category model (fresh)\ncategory_model = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=len(categories),\n    id2label=id2label_cat,\n    label2id=label2id_cat\n)\nprint(f'Category model loaded! ({len(categories)} classes)')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Category class weights\ncat_weights = compute_class_weight('balanced', classes=np.unique(train_cat_labels), y=train_cat_labels)\nprint('Category weights:')\nfor i, cat in id2label_cat.items():\n    print(f'  {cat}: {cat_weights[i]:.3f}')\n\ncat_weights_tensor = torch.tensor(cat_weights, dtype=torch.float32).to('cuda')\n\nclass WeightedTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        labels = inputs.pop('labels')\n        outputs = model(**inputs)\n        logits = outputs.logits\n        loss_fn = nn.CrossEntropyLoss(weight=cat_weights_tensor)\n        loss = loss_fn(logits, labels)\n        return (loss, outputs) if return_outputs else loss\n\ndef compute_metrics_cat(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n    return {'accuracy': accuracy_score(labels, preds), 'f1': f1, 'precision': precision, 'recall': recall}"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Train Stage 2\ncat_args = TrainingArguments(\n    output_dir='./stage2_checkpoints',\n    num_train_epochs=5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=32,\n    warmup_steps=300,\n    weight_decay=0.01,\n    logging_steps=300,\n    eval_strategy='epoch',\n    save_strategy='epoch',\n    load_best_model_at_end=True,\n    metric_for_best_model='f1',\n    fp16=True,\n    report_to='none',\n    gradient_accumulation_steps=2,\n)\n\ncategory_trainer = WeightedTrainer(\n    model=category_model,\n    args=cat_args,\n    train_dataset=train_cat_dataset,\n    eval_dataset=val_cat_dataset,\n    compute_metrics=compute_metrics_cat,\n)\n\nprint('='*60)\nprint('TRAINING STAGE 2: Category Classifier')\nprint('='*60)\ncategory_trainer.train()"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Evaluate Stage 2\nresults2 = category_trainer.evaluate()\nprint(f'\\n{\"=\"*60}')\nprint('STAGE 2 RESULTS')\nprint(f'{\"=\"*60}')\nprint(f'Accuracy:  {results2[\"eval_accuracy\"]:.4f}')\nprint(f'F1:        {results2[\"eval_f1\"]:.4f}')\nprint(f'Precision: {results2[\"eval_precision\"]:.4f}')\nprint(f'Recall:    {results2[\"eval_recall\"]:.4f}')\n\n# Detailed report\npreds = category_trainer.predict(val_cat_dataset)\npred_labels = preds.predictions.argmax(-1)\nprint('\\nClassification Report:')\nprint(classification_report(val_cat_labels, pred_labels, target_names=categories))"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Save Stage 2\ncategory_model.save_pretrained('moe_muril/stage2_category')\ntokenizer.save_pretrained('moe_muril/stage2_category')\nprint('✅ Stage 2 saved to moe_muril/stage2_category')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "markdown", "source": ["---\n", "## Test Complete Pipeline"], "metadata": {}},
    
    {"cell_type": "code", "source": ["from transformers import pipeline\n\n# Load both stages\nstage1 = pipeline('text-classification', model='moe_muril/stage1_binary', device=0)\nstage2 = pipeline('text-classification', model='moe_muril/stage2_category', device=0)\n\ndef classify(text):\n    # Stage 1\n    r1 = stage1(text)[0]\n    if r1['label'] == 'safe':\n        return {'toxic': False, 'category': 'safe', 'conf': r1['score']}\n    \n    # Stage 2\n    r2 = stage2(text)[0]\n    return {\n        'toxic': True, \n        'category': r2['label'], \n        'conf': r1['score'] * r2['score']\n    }\n\nprint('Pipeline ready!')"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Critical tests\ntests = [\n    # Safe\n    ('Hello, how are you?', 'safe', False),\n    ('The weather is nice', 'safe', False),\n    ('namaste kaise ho', 'safe', False),\n    ('I went back to my country for vacation', 'safe', False),\n    \n    # Harmful\n    ('I will kill you', 'harmful_content', True),\n    ('how to make a bomb', 'harmful_content', True),\n    ('how to make an explosive device', 'harmful_content', True),\n    ('I will shoot you', 'harmful_content', True),\n    \n    # Hindi\n    ('bhenchod', 'hindi_abuse', True),\n    ('madarchod', 'hindi_abuse', True),\n    ('chutiya', 'hindi_abuse', True),\n    ('teri maa ki', 'hindi_abuse', True),\n    ('tu bekaar insaan hai', 'hindi_abuse', True),\n    \n    # Harassment\n    ('you are worthless garbage', 'harassment', True),\n    ('you are so stupid', 'harassment', True),\n    ('nobody likes you', 'harassment', True),\n    ('your kind disgusts me', 'harassment', True),\n    \n    # Hate\n    ('go back to your country', 'hate_speech', True),\n    ('all immigrants should be deported', 'hate_speech', True),\n    ('people like you should not exist', 'hate_speech', True),\n    \n    # Self-harm\n    ('I want to kill myself', 'self_harm', True),\n    ('I want to end my life', 'self_harm', True),\n    ('kys', 'self_harm', True),\n    \n    # Sexual\n    ('send nudes', 'sexual', True),\n    ('I want to see you naked', 'sexual', True),\n]\n\nprint('='*80)\nprint('CRITICAL TEST CASES')\nprint('='*80)\n\ntoxic_ok = 0\ntoxic_total = 0\ncat_ok = 0\ncat_total = 0\n\nfor text, exp_cat, exp_toxic in tests:\n    r = classify(text)\n    \n    # Toxic detection\n    if exp_toxic:\n        toxic_total += 1\n        if r['toxic']: toxic_ok += 1\n    \n    # Category\n    if exp_toxic and r['toxic']:\n        cat_total += 1\n        if r['category'] == exp_cat: cat_ok += 1\n    \n    t_ok = '✅' if r['toxic'] == exp_toxic else '❌'\n    c_ok = '✅' if r['category'] == exp_cat else '❌'\n    \n    print(f\"{t_ok}{c_ok} {r['category']:<18} | exp: {exp_cat:<18} | {text[:35]}\")\n\nprint()\nprint('='*80)\nprint(f'TOXIC DETECTION: {toxic_ok}/{toxic_total} ({100*toxic_ok/toxic_total:.0f}%) - Target: 95%+')\nprint(f'CATEGORY:        {cat_ok}/{cat_total} ({100*cat_ok/cat_total:.0f}%) - Target: 80%+')\nprint('='*80)"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Summary\nprint('\\n' + '='*60)\nprint('FINAL SUMMARY')\nprint('='*60)\nprint(f'Model: {MODEL_NAME}')\nprint(f'\\nStage 1 (Binary):')\nprint(f'  Recall: {results1[\"eval_recall\"]:.2%}')\nprint(f'  F1:     {results1[\"eval_f1\"]:.2%}')\nprint(f'\\nStage 2 (Category):')\nprint(f'  F1:     {results2[\"eval_f1\"]:.2%}')\nprint('='*60)"], "metadata": {}, "execution_count": null, "outputs": []},
    
    {"cell_type": "code", "source": ["# Download\n!zip -r moe_muril.zip moe_muril/\nfiles.download('moe_muril.zip')"], "metadata": {}, "execution_count": null, "outputs": []}
  ]
}
